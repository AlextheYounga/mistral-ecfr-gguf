#!/bin/bash

# Run from workspace dir
# Download the llama.cpp library and build it

cd ..
git clone https://github.com/ggml-org/llama.cpp.git lib/llama.cpp
mkdir -p lib/llama.cpp
cd lib/llama.cpp


# CPU is default.
# MacOS Metal GPU support is on by default.
# For CUDA support, you may want to download from a stable release, because building for CUDA seems error prone. (-DGGML_CUDA=ON)
cmake -B build 
cmake --build build --config Release